{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from mlflow.data.pandas_dataset import PandasDataset\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, ElasticNet\n",
    "from tqdm import tqdm\n",
    "from mlflow.models import infer_signature\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %store -r X y\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.33, random_state=42, stratify=y\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler = StandardScaler().set_output(transform=\"pandas\")\n",
    "X_train = std_scaler.fit_transform(X_train)\n",
    "X_test = std_scaler.transform(X_test)\n",
    "\n",
    "# dataset_train = mlflow.data.from_pandas(\n",
    "#     X_train, targets=y_train, name=\"credit-score-classification-train\"\n",
    "# )\n",
    "# dataset_test = mlflow.data.from_pandas(\n",
    "#     X_test, targets=y_test, name=\"credit-score-classification-test\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow_user magical_password mlflow_db\n"
     ]
    }
   ],
   "source": [
    "# Указываем доступ в БД\n",
    "# with open(\"../database.env\", \"r\") as file:\n",
    "with open(\"database.env\", \"r\") as file:    \n",
    "    lines = file.readlines()\n",
    "    user = lines[0].split(\"=\")[-1][:-1]\n",
    "    password = lines[1].split(\"=\")[-1][:-1]\n",
    "    db = lines[2].split(\"=\")[-1]\n",
    "print(user, password, db)\n",
    "sql_string = f\"postgresql://{user}:{password}@postgres:5432/{db}\"\n",
    "mlflow.set_tracking_uri(sql_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, ElasticNet\n",
    "\n",
    "models = [\n",
    "    [\n",
    "        \n",
    "        LogisticRegression(random_state=42),\n",
    "        {\n",
    "            \"C\": [0.01, 0.1, 1, 10, 100],\n",
    "            \"solver\": [\n",
    "                \"liblinear\",\n",
    "                \"saga\",\n",
    "            ],  # solvers that support multiclass classification\n",
    "            \"penalty\": [\"l1\", \"l2\", \"elasticnet\"],  # l1 = Lasso, l2 = Ridge\n",
    "            \"max_iter\": [100, 200, 500],\n",
    "        },\n",
    "    \n",
    "    ]\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(experiment_name, suffix=None):\n",
    "    try:\n",
    "        experiment_id = mlflow.create_experiment(experiment_name)\n",
    "    except mlflow.exceptions.MlflowException:\n",
    "        experiment_id = mlflow.get_experiment_by_name(experiment_name).experiment_id\n",
    "        \n",
    "    for model in models:\n",
    "        if suffix == None:\n",
    "            run_n = model[0].__class__.__name__\n",
    "        else:\n",
    "            run_n = model[0].__class__.__name__+suffix\n",
    "        with mlflow.start_run(experiment_id=experiment_id, run_name=run_n):\n",
    "            mlflow.log_param(\"Model\", model[0].__class__.__name__)\n",
    "            grid_search = GridSearchCV(\n",
    "                estimator=model[0],\n",
    "                param_grid=model[1],\n",
    "                cv=5,  \n",
    "                scoring='accuracy',\n",
    "                n_jobs=-1,\n",
    "            )\n",
    "            signature = infer_signature(X_test, y_test)\n",
    "            # Train the model and find the best parameters\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            mlflow.log_params(grid_search.best_params_)\n",
    "            best_model = grid_search.best_estimator_\n",
    "    \n",
    "            # mlflow.log_input(dataset_train, context=\"training\")\n",
    "            # mlflow.log_input(dataset_test, context=\"evaluation\")\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred, average='weighted')\n",
    "            recall = recall_score(y_test, y_pred, average='weighted')\n",
    "            f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "            model_uri = mlflow.sklearn.log_model(\n",
    "                                best_model, \"model\", signature=signature\n",
    "                            ).model_uri \n",
    "            mlflow.evaluate(\n",
    "                model_uri,\n",
    "                pd.concat([X_test, y_test], axis=1),\n",
    "                targets=\"Credit_Score\",\n",
    "                model_type=\"classifier\",\n",
    "            )\n",
    "            mlflow.log_metric(\"accuracy\", accuracy)\n",
    "            mlflow.log_metric(\"precision\", precision)\n",
    "            mlflow.log_metric(\"recall\", recall)\n",
    "            mlflow.log_metric(\"f1_score\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/mlflow_env/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/mlflow_env/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/mlflow_env/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/mlflow_env/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/mlflow_env/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/mlflow_env/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/mlflow_env/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/mlflow_env/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/mlflow_env/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/mlflow_env/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/mlflow_env/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/mlflow_env/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/mlflow_env/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/mlflow_env/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/mlflow_env/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/mlflow_env/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/mlflow_env/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/mlflow_env/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/mlflow_env/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/mlflow_env/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/mlflow_env/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/mlflow_env/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/mlflow_env/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/mlflow_env/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/mlflow_env/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/mlflow_env/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:547: FitFailedWarning: \n",
      "150 fits failed out of a total of 450.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/mlflow_env/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/envs/mlflow_env/lib/python3.12/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/envs/mlflow_env/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/envs/mlflow_env/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 75, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/mlflow_env/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/envs/mlflow_env/lib/python3.12/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/envs/mlflow_env/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 1182, in fit\n",
      "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
      "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/conda/envs/mlflow_env/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.67010092 0.67355153 0.67143188 0.67485772        nan        nan\n",
      " 0.67010092 0.67355153 0.67143188 0.67485772        nan        nan\n",
      " 0.67010092 0.67355153 0.67143188 0.67485772        nan        nan\n",
      " 0.67130863 0.67493167 0.67150581 0.67475915        nan        nan\n",
      " 0.67130863 0.67493167 0.67150581 0.67475915        nan        nan\n",
      " 0.67130863 0.67493167 0.67150581 0.67475915        nan        nan\n",
      " 0.671703   0.6747345  0.67148117 0.67468521        nan        nan\n",
      " 0.671703   0.6747345  0.67148117 0.67468521        nan        nan\n",
      " 0.671703   0.6747345  0.67148117 0.67468521        nan        nan\n",
      " 0.67153046 0.67470986 0.67145652 0.6747345         nan        nan\n",
      " 0.67153046 0.67470986 0.67145652 0.6747345         nan        nan\n",
      " 0.67153046 0.67470986 0.67145652 0.6747345         nan        nan\n",
      " 0.67148116 0.6747345  0.67145652 0.6747345         nan        nan\n",
      " 0.67148116 0.6747345  0.67145652 0.6747345         nan        nan\n",
      " 0.67148116 0.6747345  0.67145652 0.6747345         nan        nan]\n",
      "  warnings.warn(\n",
      "2024/08/29 14:47:37 WARNING mlflow.utils.validation: Tag value '[{\"run_id\": \"26da36954d5c4cdcb9ace8d766f4bed5\", \"artifact_path\": \"model\", \"utc_time_created\": \"2024-...' (5530 characters) is truncated to 5000 characters to meet the length limit.\n",
      "2024/08/29 14:47:37 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under /app/data/mlflow_artifacts/16/26da36954d5c4cdcb9ace8d766f4bed5/artifacts. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n",
      "2024/08/29 14:47:44 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n",
      "2024/08/29 14:47:44 INFO mlflow.models.evaluation.default_evaluator: The evaluation dataset is inferred as multiclass dataset, number of classes is inferred as 3. If this is incorrect, please specify the `label_list` parameter in `evaluator_config`.\n",
      "2024/08/29 14:47:44 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "2024/08/29 14:47:46 WARNING mlflow.models.evaluation.default_evaluator: Skip logging model explainability insights because it requires all label values to be numeric or boolean.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1050x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_experiment(\"Linear Models Comparison (with GridSearch on scaled)\", \"_linmodels\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
