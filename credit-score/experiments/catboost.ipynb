{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from mlflow.data.pandas_dataset import PandasDataset\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, ElasticNet\n",
    "from tqdm import tqdm\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "from catboost import Pool, CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = pd.read_pickle(\"data/processed_df.pkl\")\n",
    "X = processed.drop(columns=[\"Credit_Score\"])\n",
    "y = processed[\"Credit_Score\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42, stratify=y\n",
    ")\n",
    "std_scaler = StandardScaler().set_output(transform=\"pandas\")\n",
    "X_train = std_scaler.fit_transform(X_train)\n",
    "X_test = std_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_catboost_experiment(experiment_name, catboost_params, suffix=None):\n",
    "    try:\n",
    "        experiment_id = mlflow.create_experiment(experiment_name)\n",
    "    except mlflow.exceptions.MlflowException:\n",
    "        experiment_id = mlflow.get_experiment_by_name(experiment_name).experiment_id\n",
    "    \n",
    "    if suffix is None:\n",
    "        run_n = \"CatBoost\"\n",
    "    else:\n",
    "        run_n = \"CatBoost\" + suffix\n",
    "\n",
    "    with mlflow.start_run(experiment_id=experiment_id, run_name=run_n):\n",
    "        # mlflow.log_params(catboost_params)\n",
    "        \n",
    "        # Prepare the dataset for CatBoost\n",
    "        train_pool = Pool(X_train, y_train)\n",
    "        test_pool = Pool(X_test, y_test)\n",
    "        base_params = {\n",
    "            'logging_level':'Silent',\n",
    "            'loss_function':'MultiClass',\n",
    "            'l2_leaf_reg': 3,\n",
    "            'random_strength': 1.2,\n",
    "        }\n",
    "        cat_param = CatBoostClassifier(**base_params)\n",
    "        search = cat_param.grid_search(catboost_params, train_pool, cv=5)\n",
    "        cat_param.fit(train_pool, use_best_model=True, eval_set=test_pool)\n",
    "\n",
    "        # Extract the best model parameters (for logging)\n",
    "        best_params = search['params']\n",
    "        mlflow.log_params(best_params)\n",
    "\n",
    "        # Train the best model on the full training set\n",
    "        model = CatBoostClassifier(**(best_params | base_params))\n",
    "        model.fit(train_pool, verbose=False)\n",
    "        \n",
    "        # Model evaluation\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='weighted')\n",
    "        recall = recall_score(y_test, y_pred, average='weighted')\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        \n",
    "        # Log model and evaluation metrics\n",
    "        signature = infer_signature(X_test, y_test)\n",
    "        model_uri = mlflow.catboost.log_model(\n",
    "            model, \"model\", signature=signature\n",
    "        ).model_uri\n",
    "        \n",
    "        mlflow.evaluate(\n",
    "            model_uri,\n",
    "            test_pool,\n",
    "            targets=\"Credit_Score\",\n",
    "            model_type=\"classifier\",\n",
    "        )\n",
    "        \n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tloss: 0.7415884\tbest: 0.7415884 (0)\ttotal: 605ms\tremaining: 21.2s\n",
      "1:\tloss: 0.7137650\tbest: 0.7137650 (1)\ttotal: 1.17s\tremaining: 19.9s\n",
      "2:\tloss: 0.6980854\tbest: 0.6980854 (2)\ttotal: 1.7s\tremaining: 18.7s\n",
      "3:\tloss: 0.6830882\tbest: 0.6830882 (3)\ttotal: 3.48s\tremaining: 27.9s\n",
      "4:\tloss: 0.6738794\tbest: 0.6738794 (4)\ttotal: 5.1s\tremaining: 31.6s\n",
      "5:\tloss: 0.6673806\tbest: 0.6673806 (5)\ttotal: 6.85s\tremaining: 34.3s\n",
      "6:\tloss: 0.6710913\tbest: 0.6673806 (5)\ttotal: 9.67s\tremaining: 40s\n",
      "7:\tloss: 0.6630521\tbest: 0.6630521 (7)\ttotal: 12.2s\tremaining: 42.7s\n",
      "8:\tloss: 0.6570961\tbest: 0.6570961 (8)\ttotal: 14.7s\tremaining: 44.1s\n",
      "9:\tloss: 0.6609704\tbest: 0.6570961 (8)\ttotal: 18.5s\tremaining: 48.1s\n",
      "10:\tloss: 0.6537773\tbest: 0.6537773 (10)\ttotal: 22.3s\tremaining: 50.6s\n",
      "11:\tloss: 0.6486150\tbest: 0.6486150 (11)\ttotal: 26.2s\tremaining: 52.4s\n",
      "12:\tloss: 0.7183731\tbest: 0.6486150 (11)\ttotal: 26.8s\tremaining: 47.4s\n",
      "13:\tloss: 0.6898757\tbest: 0.6486150 (11)\ttotal: 27.4s\tremaining: 43s\n",
      "14:\tloss: 0.6768585\tbest: 0.6486150 (11)\ttotal: 28s\tremaining: 39.1s\n",
      "15:\tloss: 0.6649705\tbest: 0.6486150 (11)\ttotal: 29.7s\tremaining: 37.2s\n",
      "16:\tloss: 0.6564861\tbest: 0.6486150 (11)\ttotal: 31.5s\tremaining: 35.2s\n",
      "17:\tloss: 0.6505443\tbest: 0.6486150 (11)\ttotal: 33.2s\tremaining: 33.2s\n",
      "18:\tloss: 0.6550136\tbest: 0.6486150 (11)\ttotal: 36.1s\tremaining: 32.3s\n",
      "19:\tloss: 0.6467486\tbest: 0.6467486 (19)\ttotal: 38.9s\tremaining: 31.1s\n",
      "20:\tloss: 0.6414358\tbest: 0.6414358 (20)\ttotal: 41.8s\tremaining: 29.8s\n",
      "21:\tloss: 0.6446544\tbest: 0.6414358 (20)\ttotal: 46.4s\tremaining: 29.5s\n",
      "22:\tloss: 0.6375479\tbest: 0.6375479 (22)\ttotal: 51.1s\tremaining: 28.9s\n",
      "23:\tloss: 0.6331331\tbest: 0.6331331 (23)\ttotal: 56.3s\tremaining: 28.1s\n",
      "24:\tloss: 0.7036069\tbest: 0.6331331 (23)\ttotal: 57s\tremaining: 25.1s\n",
      "25:\tloss: 0.6777609\tbest: 0.6331331 (23)\ttotal: 57.7s\tremaining: 22.2s\n",
      "26:\tloss: 0.6666101\tbest: 0.6331331 (23)\ttotal: 58.5s\tremaining: 19.5s\n",
      "27:\tloss: 0.6554321\tbest: 0.6331331 (23)\ttotal: 1m\tremaining: 17.3s\n",
      "28:\tloss: 0.6474331\tbest: 0.6331331 (23)\ttotal: 1m 2s\tremaining: 15.2s\n",
      "29:\tloss: 0.6407266\tbest: 0.6331331 (23)\ttotal: 1m 4s\tremaining: 13s\n",
      "30:\tloss: 0.6445947\tbest: 0.6331331 (23)\ttotal: 1m 8s\tremaining: 11.1s\n",
      "31:\tloss: 0.6358838\tbest: 0.6331331 (23)\ttotal: 1m 12s\tremaining: 9.02s\n",
      "32:\tloss: 0.6289179\tbest: 0.6289179 (32)\ttotal: 1m 15s\tremaining: 6.87s\n",
      "33:\tloss: 0.6337133\tbest: 0.6289179 (32)\ttotal: 1m 21s\tremaining: 4.78s\n",
      "34:\tloss: 0.6253403\tbest: 0.6253403 (34)\ttotal: 1m 26s\tremaining: 2.48s\n",
      "35:\tloss: 0.6187994\tbest: 0.6187994 (35)\ttotal: 1m 32s\tremaining: 0us\n",
      "Estimating final quality...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/29 15:50:09 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under /app/data/mlflow_artifacts/21/6ad8f41ad7a146269d439347f2f8169c/artifacts. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n",
      "2024/08/29 15:50:16 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n",
      "2024/08/29 15:50:16 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run CatBoost at: http://0.0.0.0:5000/#/experiments/21/runs/6ad8f41ad7a146269d439347f2f8169c.\n",
      "2024/08/29 15:50:16 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: http://0.0.0.0:5000/#/experiments/21.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_catboost_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGridSearchCV_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdepth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlearning_rate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.02\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.03\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.04\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43miterations\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m800\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 50\u001b[0m, in \u001b[0;36mrun_catboost_experiment\u001b[0;34m(experiment_name, catboost_params, suffix)\u001b[0m\n\u001b[1;32m     45\u001b[0m signature \u001b[38;5;241m=\u001b[39m infer_signature(X_test, y_test)\n\u001b[1;32m     46\u001b[0m model_uri \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39mcatboost\u001b[38;5;241m.\u001b[39mlog_model(\n\u001b[1;32m     47\u001b[0m     model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, signature\u001b[38;5;241m=\u001b[39msignature\n\u001b[1;32m     48\u001b[0m )\u001b[38;5;241m.\u001b[39mmodel_uri\n\u001b[0;32m---> 50\u001b[0m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtargets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCredit_Score\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclassifier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_metric(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy)\n\u001b[1;32m     58\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_metric(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m\"\u001b[39m, precision)\n",
      "File \u001b[0;32m/opt/conda/envs/mlflow_env/lib/python3.12/site-packages/mlflow/models/evaluation/base.py:1608\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, data, model_type, targets, predictions, dataset_path, feature_names, evaluators, evaluator_config, custom_metrics, extra_metrics, custom_artifacts, validation_thresholds, baseline_model, env_manager, model_config, baseline_config, inference_params)\u001b[0m\n\u001b[1;32m   1605\u001b[0m predictions_expected_in_model_output \u001b[38;5;241m=\u001b[39m predictions \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1607\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1608\u001b[0m     evaluate_result \u001b[38;5;241m=\u001b[39m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluator_name_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluator_name_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1614\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluator_name_to_conf_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluator_name_to_conf_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1615\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1616\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1617\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_artifacts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_artifacts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1618\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbaseline_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbaseline_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1619\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredictions_expected_in_model_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1620\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1621\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1622\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, _ServedPyFuncModel):\n",
      "File \u001b[0;32m/opt/conda/envs/mlflow_env/lib/python3.12/site-packages/mlflow/models/evaluation/base.py:786\u001b[0m, in \u001b[0;36m_evaluate\u001b[0;34m(model, model_type, dataset, run_id, evaluator_name_list, evaluator_name_to_conf_map, custom_metrics, extra_metrics, custom_artifacts, baseline_model, predictions)\u001b[0m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m evaluator\u001b[38;5;241m.\u001b[39mcan_evaluate(model_type\u001b[38;5;241m=\u001b[39mmodel_type, evaluator_config\u001b[38;5;241m=\u001b[39mconfig):\n\u001b[1;32m    785\u001b[0m         _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating the model with the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevaluator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m evaluator.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 786\u001b[0m         eval_result \u001b[38;5;241m=\u001b[39m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mevaluator_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcustom_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcustom_artifacts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_artifacts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbaseline_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbaseline_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    798\u001b[0m         eval_results\u001b[38;5;241m.\u001b[39mappend(eval_result)\n\u001b[1;32m    800\u001b[0m _last_failed_evaluator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/mlflow_env/lib/python3.12/site-packages/mlflow/models/evaluation/default_evaluator.py:2110\u001b[0m, in \u001b[0;36mDefaultEvaluator.evaluate\u001b[0;34m(self, model_type, dataset, run_id, evaluator_config, model, custom_metrics, extra_metrics, custom_artifacts, baseline_model, predictions, **kwargs)\u001b[0m\n\u001b[1;32m   2108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m baseline_model:\n\u001b[1;32m   2109\u001b[0m         _logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating candidate model:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2110\u001b[0m     evaluation_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_baseline_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m baseline_model:\n\u001b[1;32m   2113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m evaluation_result\n",
      "File \u001b[0;32m/opt/conda/envs/mlflow_env/lib/python3.12/site-packages/mlflow/models/evaluation/default_evaluator.py:1974\u001b[0m, in \u001b[0;36mDefaultEvaluator._evaluate\u001b[0;34m(self, model, is_baseline_model, **kwargs)\u001b[0m\n\u001b[1;32m   1972\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m extra_metric\u001b[38;5;241m.\u001b[39mgenai_metric_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1973\u001b[0m         genai_custom_metrics\u001b[38;5;241m.\u001b[39mappend(extra_metric\u001b[38;5;241m.\u001b[39mgenai_metric_args)\n\u001b[0;32m-> 1974\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_model_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompute_latency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_latency\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1975\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_builtin_metrics_by_model_type()\n\u001b[1;32m   1977\u001b[0m eval_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m: copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_pred)})\n",
      "File \u001b[0;32m/opt/conda/envs/mlflow_env/lib/python3.12/site-packages/mlflow/models/evaluation/default_evaluator.py:1520\u001b[0m, in \u001b[0;36mDefaultEvaluator._generate_model_predictions\u001b[0;34m(self, compute_latency)\u001b[0m\n\u001b[1;32m   1517\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mpredictions_data\n\u001b[1;32m   1519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_list \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_list \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_pred\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1521\u001b[0m \u001b[38;5;66;03m# sort label_list ASC, for binary classification it makes sure the last one is pos label\u001b[39;00m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_list\u001b[38;5;241m.\u001b[39msort()\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)"
     ]
    }
   ],
   "source": [
    "run_catboost_experiment(\"GridSearchCV_\", {\n",
    "    'depth': [2, 3, 4],\n",
    "    'learning_rate': [0.02, 0.03, 0.04],\n",
    "    'iterations' : [100, 300, 500, 800],\n",
    "    })\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
