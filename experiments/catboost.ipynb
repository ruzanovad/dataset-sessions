{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from mlflow.data.pandas_dataset import PandasDataset\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, ElasticNet\n",
    "from tqdm import tqdm\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "from catboost import Pool, CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = pd.read_pickle(\"data/processed_df.pkl\")\n",
    "X = processed.drop(columns=[\"Credit_Score\"])\n",
    "y = processed[\"Credit_Score\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42, stratify=y\n",
    ")\n",
    "std_scaler = StandardScaler().set_output(transform=\"pandas\")\n",
    "X_train = std_scaler.fit_transform(X_train)\n",
    "X_test = std_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCatboostClassifier(CatBoostClassifier, mlflow.pyfunc.PythonModel):\n",
    "    def predict(data,\n",
    "        prediction_type='Class',\n",
    "        ntree_start=0,\n",
    "        ntree_end=0,\n",
    "        thread_count=-1,\n",
    "        verbose=None):\n",
    "        result = super(CatBoostClassifier).predict(data,\n",
    "            prediction_type='Class',\n",
    "            ntree_start=0,\n",
    "            ntree_end=0,\n",
    "            thread_count=-1,\n",
    "            verbose=None)\n",
    "        if isinstance(result, np.ndarray):\n",
    "            return result.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_catboost_experiment(experiment_name, catboost_params, suffix=None):\n",
    "    try:\n",
    "        experiment_id = mlflow.create_experiment(experiment_name)\n",
    "    except mlflow.exceptions.MlflowException:\n",
    "        experiment_id = mlflow.get_experiment_by_name(experiment_name).experiment_id\n",
    "    \n",
    "    if suffix is None:\n",
    "        run_n = \"CatBoost\"\n",
    "    else:\n",
    "        run_n = \"CatBoost\" + suffix\n",
    "\n",
    "    with mlflow.start_run(experiment_id=experiment_id, run_name=run_n):\n",
    "        # mlflow.log_params(catboost_params)\n",
    "        \n",
    "        # Prepare the dataset for CatBoost\n",
    "        train_pool = Pool(X_train, y_train)\n",
    "        test_pool = Pool(X_test, y_test)\n",
    "        base_params = {\n",
    "            'logging_level':'Silent',\n",
    "            'loss_function':'MultiClass',\n",
    "            'l2_leaf_reg': 3,\n",
    "            'random_strength': 1.2,\n",
    "        }\n",
    "        cat_param = CatBoostClassifier(**base_params)\n",
    "        search = cat_param.grid_search(catboost_params, train_pool, cv=5)\n",
    "        cat_param.fit(train_pool, use_best_model=True, eval_set=test_pool)\n",
    "\n",
    "        # Extract the best model parameters (for logging)\n",
    "        best_params = search['params']\n",
    "        mlflow.log_params((best_params | base_params))\n",
    "\n",
    "        # Train the best model on the full training set\n",
    "        model = CatBoostClassifier(**(best_params | base_params))\n",
    "        model.fit(train_pool, verbose=False)\n",
    "        \n",
    "        # Model evaluation\n",
    "        # y_pred = model.predict(X_test).ravel()\n",
    "        # print(y_pred)\n",
    "        # print(type(y_pred))\n",
    "        # print(y_pred.shape)\n",
    "        # print(pd.Series(y_pred, name=\"pred\"))\n",
    "\n",
    "        # log the model into a mlflow ru\n",
    "    \n",
    "        # accuracy = accuracy_score(y_test, y_pred)\n",
    "        # precision = precision_score(y_test, y_pred, average='weighted')\n",
    "        # recall = recall_score(y_test, y_pred, average='weighted')\n",
    "        # f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        \n",
    "        # Log model and evaluation metrics\n",
    "        # signature = infer_signature(X_test, y_test)\n",
    "        \n",
    "        mlflow.evaluate(\n",
    "            lambda x: model.predict(x).ravel(),\n",
    "            pd.concat([X_test, y_test], axis=1),\n",
    "            targets=\"Credit_Score\",\n",
    "            model_type=\"classifier\",\n",
    "        )\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tloss: 0.7415884\tbest: 0.7415884 (0)\ttotal: 610ms\tremaining: 21.3s\n",
      "1:\tloss: 0.7137650\tbest: 0.7137650 (1)\ttotal: 1.19s\tremaining: 20.2s\n",
      "2:\tloss: 0.6980854\tbest: 0.6980854 (2)\ttotal: 1.81s\tremaining: 20s\n",
      "3:\tloss: 0.6830882\tbest: 0.6830882 (3)\ttotal: 3.58s\tremaining: 28.6s\n",
      "4:\tloss: 0.6738794\tbest: 0.6738794 (4)\ttotal: 5.4s\tremaining: 33.5s\n",
      "5:\tloss: 0.6673806\tbest: 0.6673806 (5)\ttotal: 7.13s\tremaining: 35.7s\n",
      "6:\tloss: 0.6710913\tbest: 0.6673806 (5)\ttotal: 9.76s\tremaining: 40.4s\n",
      "7:\tloss: 0.6630521\tbest: 0.6630521 (7)\ttotal: 12.4s\tremaining: 43.5s\n",
      "8:\tloss: 0.6570961\tbest: 0.6570961 (8)\ttotal: 15.1s\tremaining: 45.3s\n",
      "9:\tloss: 0.6609704\tbest: 0.6570961 (8)\ttotal: 19.4s\tremaining: 50.5s\n",
      "10:\tloss: 0.6537773\tbest: 0.6537773 (10)\ttotal: 23.6s\tremaining: 53.7s\n",
      "11:\tloss: 0.6486150\tbest: 0.6486150 (11)\ttotal: 27.9s\tremaining: 55.8s\n",
      "12:\tloss: 0.7183731\tbest: 0.6486150 (11)\ttotal: 28.5s\tremaining: 50.5s\n",
      "13:\tloss: 0.6898757\tbest: 0.6486150 (11)\ttotal: 29.2s\tremaining: 45.9s\n",
      "14:\tloss: 0.6768585\tbest: 0.6486150 (11)\ttotal: 29.8s\tremaining: 41.8s\n",
      "15:\tloss: 0.6649705\tbest: 0.6486150 (11)\ttotal: 31.8s\tremaining: 39.7s\n",
      "16:\tloss: 0.6564861\tbest: 0.6486150 (11)\ttotal: 33.7s\tremaining: 37.7s\n",
      "17:\tloss: 0.6505443\tbest: 0.6486150 (11)\ttotal: 35.6s\tremaining: 35.6s\n",
      "18:\tloss: 0.6550136\tbest: 0.6486150 (11)\ttotal: 38.8s\tremaining: 34.7s\n",
      "19:\tloss: 0.6467486\tbest: 0.6467486 (19)\ttotal: 42s\tremaining: 33.6s\n",
      "20:\tloss: 0.6414358\tbest: 0.6414358 (20)\ttotal: 45.1s\tremaining: 32.2s\n",
      "21:\tloss: 0.6446544\tbest: 0.6414358 (20)\ttotal: 50.1s\tremaining: 31.9s\n",
      "22:\tloss: 0.6375479\tbest: 0.6375479 (22)\ttotal: 55.1s\tremaining: 31.2s\n",
      "23:\tloss: 0.6331331\tbest: 0.6331331 (23)\ttotal: 1m\tremaining: 30.1s\n",
      "24:\tloss: 0.7036069\tbest: 0.6331331 (23)\ttotal: 1m\tremaining: 26.8s\n",
      "25:\tloss: 0.6777609\tbest: 0.6331331 (23)\ttotal: 1m 1s\tremaining: 23.7s\n",
      "26:\tloss: 0.6666101\tbest: 0.6331331 (23)\ttotal: 1m 2s\tremaining: 20.8s\n",
      "27:\tloss: 0.6554321\tbest: 0.6331331 (23)\ttotal: 1m 4s\tremaining: 18.5s\n",
      "28:\tloss: 0.6474331\tbest: 0.6331331 (23)\ttotal: 1m 7s\tremaining: 16.2s\n",
      "29:\tloss: 0.6407266\tbest: 0.6331331 (23)\ttotal: 1m 9s\tremaining: 13.8s\n",
      "30:\tloss: 0.6445947\tbest: 0.6331331 (23)\ttotal: 1m 12s\tremaining: 11.8s\n",
      "31:\tloss: 0.6358838\tbest: 0.6331331 (23)\ttotal: 1m 16s\tremaining: 9.58s\n",
      "32:\tloss: 0.6289179\tbest: 0.6289179 (32)\ttotal: 1m 20s\tremaining: 7.3s\n",
      "33:\tloss: 0.6337133\tbest: 0.6289179 (32)\ttotal: 1m 26s\tremaining: 5.07s\n",
      "34:\tloss: 0.6253403\tbest: 0.6253403 (34)\ttotal: 1m 31s\tremaining: 2.63s\n",
      "35:\tloss: 0.6187994\tbest: 0.6187994 (35)\ttotal: 1m 37s\tremaining: 0us\n",
      "Estimating final quality...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/29 17:16:13 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n",
      "2024/08/29 17:16:13 INFO mlflow.models.evaluation.default_evaluator: The evaluation dataset is inferred as multiclass dataset, number of classes is inferred as 3. If this is incorrect, please specify the `label_list` parameter in `evaluator_config`.\n",
      "2024/08/29 17:16:13 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "2024/08/29 17:16:13 WARNING mlflow.models.evaluation.default_evaluator: Skip logging model explainability insights because it requires all label values to be numeric or boolean.\n",
      "2024/08/29 17:16:13 INFO mlflow.tracking._tracking_service.client: üèÉ View run CatBoost at: http://0.0.0.0:5000/#/experiments/21/runs/1017280dbfa947f18a827534e1c0fbbe.\n",
      "2024/08/29 17:16:13 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://0.0.0.0:5000/#/experiments/21.\n"
     ]
    }
   ],
   "source": [
    "run_catboost_experiment(\"GridSearchCV_\", {\n",
    "    'depth': [2, 3, 4],\n",
    "    'learning_rate': [0.02, 0.03, 0.04],\n",
    "    'iterations' : [100, 300, 500, 800],\n",
    "    })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
